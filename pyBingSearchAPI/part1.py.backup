#!/bin/python
import re
import os
import math
import json
import random
import pprint

from bing_search_api import *
from sets import Set

pp = pprint.PrettyPrinter(depth = 6)
"""
This is a class which calls the BingSearchAPI to get the top 30 results for that query

"""
class Search():
    def __init__(self, key):
        self.key = key

    def search_query(self, query):
        #Use the BingSearchAPI class to call the bing api and get the search results for the query
        bing = BingSearchAPI(self.key)
        params = {'$format': 'json',
                  '$top': 10}
        result =  bing.search(query,params)
            
        #Check the status of the result. If it is anything other than 200 OK, then return nothing
        if (result.status_code != 200):
            print "Error in retrieving document. Error is %s" %(result.status_code)
            return None
        result = (json.loads(result.text))['d']['results']
        """
        params = {'$format': 'json',
                  '$top': 15, 
                  '$skip': 15}

        bing = BingSearchAPI(self.key)
        result2 =  bing.search(query,params)
        if (result2.status_code != 200):
            print "Status is %d" %(result2.status_code)
            os.__exit(0)
        result.extend((json.loads(result2.text))['d']['results'])
        """
        return result
         #Extract the results from the text

"""
This class processess the results, computing tf-idfs for a set of results
"""
class process_results():
    def __init__(self, key):
        self.key = key
        self.tf_idf = {}
        self.result_set = {}
        self.doc_topic = {}
        self.doc = 0
        self.dim = {}
    
    def query(self, query):
       search = Search(self.key)
       search_result = search.search_query(query) 
      
       for result in search_result:
            text_doc = result['Description'] + " "+result['Title']; 
            self.result_set[self.doc] = text_doc
            self.doc_topic[self.doc] = query
            self.doc = self.doc + 1
       return self.result_set, self.doc_topic 

    def compute_tf_idf(self):
        idf = {}
        for doc_id, result in self.result_set.iteritems():
            result = result.lower()
            local_dict = {}
            words = re.split(r'\W+', result)

            #compute the frequency of each word in the document
            for word in words:
                if word in local_dict:
                    local_dict[word] = local_dict[word] + 1
                else:
                    local_dict[word] = 1
           
            #update the document frequency of the words that just occured in the document
            for key, value in local_dict.iteritems():
                if key in idf:
                    idf[key] = idf[key] + 1 
                else:
                    idf[key] = 1
                #take the log vaue for the tf    
                local_dict[key] = math.log(value, 2) + 1    

            self.tf_idf[doc_id] = local_dict 
           
        # Multiply the tf with the idf to get tf_idf vector for the document   
        for doc_id, word_list in self.tf_idf.iteritems():
           dim = 0
           for word, tf in word_list.iteritems():
                self.tf_idf[doc_id][word] = tf * math.log((float) (self.doc-1)/idf[word], 2)
                dim = dim + math.pow(self.tf_idf[doc_id][word], 2)
           self.dim[doc_id] = math.pow(dim, .5)
       
        print self.tf_idf
        return self.tf_idf, self.dim, idf

    def clear(self):
        self.tf_idf = {}
        self.result_set = {}
        self.doc = 0
        self.doc_topic = {}

"""
This class implements the main clustering algorithm.
As input, it takes the tf-idf vector for each documents, and clusters these documents based on it.
"""
class Cluster():
    def __init__(self, tf_idf, dim):
        self.no_docs = len(tf_idf)
        self.tf_idf = tf_idf
        self.clusters = {}
        self.centroids = {}
        self.centroids = {}
        self.centroids_dim = {}
        self.dim = dim


    def get_initial_seeds(self, no_clusters):
        return random.sample(xrange(1, self.no_docs), no_clusters)

    def compute_cluster(self, doc_vector, dim):
        max_diff = 0
        #print "============================"
        for key, cent in self.centroids.iteritems():
            mean_diff = 0
            for word in doc_vector.keys():
                if word in cent.keys():
                    mean_diff = mean_diff + abs(cent[word] * doc_vector[word])

            mean_diff = mean_diff / (dim * self.centroids_dim[key])
            #print mean_diff
            if mean_diff > max_diff:
                max_diff = mean_diff
                cluster = key
        #print "============================"
        return cluster

    def recompute_dim(self):
        for doc_id, word_list in self.centroids.iteritems():
           dim = 0
           for word, tf in word_list.iteritems():
                dim = dim + math.pow(tf, 2)
           self.centroids_dim[doc_id] = math.pow(dim, .5)
        #print "Dim is %s" %(self.centroids_dim)
        
    def recompute_cent(self, cluster_doc_list):
        for cluster in cluster_doc_list:
            tf_idf = {}
            count = 0
            for docs in cluster_doc_list[cluster]:
                count = count + 1
                for word, tf in self.tf_idf[docs].iteritems():
                    if word in tf_idf:
                        tf_idf[word] = tf_idf[word] + tf
                    else:
                        tf_idf[word] = tf

            for words in tf_idf:
                tf_idf[word] = tf_idf[word] / count
            #print "Before %s" %(self.centroids[cluster]) 
            self.centroids[cluster] = tf_idf
            #print "After %s" %(self.centroids[cluster]) 

    def get_clusters(self, no_clusters):
        num = self.get_initial_seeds(no_clusters)
        cluster_count = {}
        cluster_list = {}
        cluster_doc_list = {}
        

        for count in xrange(0, no_clusters):
            self.centroids[count] = self.tf_idf[num[count]]
            #print "Initial centeroids are %s" %(self.centroids) 
            self.centroids_dim[count] = self.dim[num[count]]
            cluster_count[count] = 0
            cluster_doc_list[count] = []

        count = 0
        while count < 3:
            count = count + 1
            #print "Iteration is %d" %(count)
            cluster_list = {}
            for i in xrange(0, no_clusters):
                cluster_count[i] = 0
                cluster_doc_list[i] = []
                
            for doc_id, doc in self.tf_idf.iteritems():
                doc_cluster = self.compute_cluster(doc, self.dim[doc_id])
                cluster_doc_list[doc_cluster].append(doc_id)
                cluster_count[doc_cluster] += 1
                if doc_cluster in cluster_list: 
                    cluster_data = cluster_list[doc_cluster]
                    #cluster_list[doc_cluster] = dict( (n, cluster_data.get(n, 0)+doc.get(n, 0)) for n in set(cluster_data)|set(doc) )
                    for word in doc:
                        if word in cluster_list:
                            cluster_list[doc_cluster][word] = cluster_list[doc_cluster][word] + doc[word]
                        else:
                            cluster_list[doc_cluster][word] = doc[word]
                    
                else:
                    cluster_list[doc_cluster] = doc

            
            for cluster_id, vector in cluster_list.iteritems():
                self.centroids[cluster_id] = dict( (n, cluster_list[cluster_id].get(n)/cluster_count[cluster_id]) for n in set(cluster_list[cluster_id]) )
            
            self.recompute_dim()
            print cluster_doc_list

if __name__ == '__main__':
    my_key = "cwszVgNF2K/L0c8xnG09xOEIxEc35oWH4Gflv9fUpug="
    search =  process_results(my_key)
    result, topic = search.query("texas aggies")

    """
    print "Result is "
    pp.pprint(result)
    """
    search.query("texas longhorns")
    search.query("duke blue devils")
    #search.query("dallas cowboys")
    #search.query("dallas mavericks")
    tf_idf, dim, idf = search.compute_tf_idf()
    """
    print "idf is:"
    pp.pprint(idf)
    print "tf_idf is:"
    pp.pprint(tf_idf)
    print "dim is:"
    pp.pprint(dim)
    """
    #clus = Cluster(tf_idf, dim)
    #clus.get_clusters(2)

